{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 匯入函式庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 932,
     "status": "ok",
     "timestamp": 1595644668953,
     "user": {
      "displayName": "蔡孟廷",
      "photoUrl": "",
      "userId": "16683234324658169721"
     },
     "user_tz": -480
    },
    "id": "Gsw2jGsMobCT"
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pandas as pd # 引用套件並縮寫為 pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 參數設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 754,
     "status": "ok",
     "timestamp": 1595644668954,
     "user": {
      "displayName": "蔡孟廷",
      "photoUrl": "",
      "userId": "16683234324658169721"
     },
     "user_tz": -480
    },
    "id": "quV9Md5A4lks"
   },
   "outputs": [],
   "source": [
    "class Config():\n",
    "    max_sequence_length = 500 # 最長序列長度為n個字\n",
    "    min_word_frequency = 3 # 出現頻率小於n的話 ; 就當成罕見字\n",
    "    \n",
    "    vocab_size = None\n",
    "    category_num = None\n",
    "    \n",
    "    choose_model = 'lstm' # 想要使用的模型 ex lstm; rnn; gru\n",
    "    embedding_dim_size =300 # 詞向量維度\n",
    "    num_layer = 1 # 層數\n",
    "    num_units = [128] # 神經元\n",
    "    learning_rate = 0.0001 # 學習率         \n",
    "    keep_prob = 0.8 \n",
    "    \n",
    "    batch_size = 64 # mini-batch\n",
    "    epoch_size = 30 # epoch\n",
    "    \n",
    "    save_path = 'best_validation' # 模型儲存檔名\n",
    "    \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ERsKSkm9obCY"
   },
   "source": [
    "# 資料載入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1043,
     "status": "ok",
     "timestamp": 1595644762761,
     "user": {
      "displayName": "蔡孟廷",
      "photoUrl": "",
      "userId": "16683234324658169721"
     },
     "user_tz": -480
    },
    "id": "yz4TxhifobCY"
   },
   "outputs": [],
   "source": [
    "stopwords=[]\n",
    "with open(r'stop.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if len(line)>0:\n",
    "            stopwords.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6154,
     "status": "ok",
     "timestamp": 1595644769452,
     "user": {
      "displayName": "蔡孟廷",
      "photoUrl": "",
      "userId": "16683234324658169721"
     },
     "user_tz": -480
    },
    "id": "Zfv4RorfobCc",
    "outputId": "026982b0-a41b-4d8c-9ef8-6bd5ad254fe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000\n",
      "14000\n",
      "6000\n",
      "6000\n",
      "280\n",
      "280\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "# 開啟 CSV 檔案\n",
    "data_train_x1,data_train_y1,data_valid_x1,data_valid_y1,data_test_x1,data_test_y1=[],[],[],[],[],[]\n",
    "\n",
    "with open(r'train.csv', newline='',encoding='utf-8') as csvfile:\n",
    "    # 讀取 CSV 檔案內容\n",
    "    rows = csv.reader(csvfile)\n",
    "    # 以迴圈輸出每一列\n",
    "    for row in rows:\n",
    "        data_train_x1.append(row[3])\n",
    "        data_train_x= data_train_x1[1:]\n",
    "        data_train_y1.append(row[5])\n",
    "        data_train_y=data_train_y1[1:]\n",
    "with open(r'test.csv', newline='',encoding='utf-8') as csvfile:\n",
    "    rows = csv.reader(csvfile)\n",
    "    for row in rows:\n",
    "        data_valid_x1.append(row[3])\n",
    "        data_valid_x=data_valid_x1[1:]\n",
    "        data_valid_y1.append(row[5])\n",
    "        data_valid_y=data_valid_y1[1:]\n",
    "with open(r'valid.csv', newline='',encoding='utf-8') as csvfile:\n",
    "    rows = csv.reader(csvfile)\n",
    "    for row in rows:\n",
    "        data_test_x1.append(row[1])\n",
    "        data_test_x=data_test_x1[1:]\n",
    "        data_test_y1.append(row[2])\n",
    "        data_test_y=data_test_y1[1:]\n",
    "print(len(data_train_x))\n",
    "print(len(data_train_y))\n",
    "print(len(data_valid_x))\n",
    "print(len(data_valid_y))\n",
    "print(len(data_test_x))\n",
    "print(len(data_test_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6409,
     "status": "ok",
     "timestamp": 1595644770367,
     "user": {
      "displayName": "蔡孟廷",
      "photoUrl": "",
      "userId": "16683234324658169721"
     },
     "user_tz": -480
    },
    "id": "Mf-U3uQxobCf",
    "outputId": "d58065fb-2872-4ada-ab92-832c1a007423"
   },
   "outputs": [],
   "source": [
    "def clean_text(text_string):\n",
    "    text_string = re.sub(r'[^\\u4e00-\\u9fa5]+', '', text_string)\n",
    "    return(text_string)\n",
    "# Clean texts\n",
    "data_train_x = [clean_text(x) for x in data_train_x]\n",
    "data_valid_x = [clean_text(x) for x in data_valid_x]\n",
    "data_test_x = [clean_text(x) for x in data_test_x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6184,
     "status": "ok",
     "timestamp": 1595644770368,
     "user": {
      "displayName": "蔡孟廷",
      "photoUrl": "",
      "userId": "16683234324658169721"
     },
     "user_tz": -480
    },
    "id": "DQimlbMzyHbq",
    "outputId": "3e412615-2d2e-4f65-ecb2-3d3e9b712bc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清洗前trian:14000,清洗前trian_target:14000\n",
      "清洗後trian:13413,清洗後trian_target:13413\n",
      "清洗前test:6000,清洗前test:6000\n",
      "清洗後test:5804,清洗後test_target:5804\n",
      "清洗前valid:280,清洗前valid:280\n",
      "清洗後valid:270,清洗後valid_target:270\n"
     ]
    }
   ],
   "source": [
    "clean_train_x = []\n",
    "clean_train_y = []\n",
    "clean_vaild_x = []\n",
    "clean_valid_y = []\n",
    "clean_test_x = []\n",
    "clean_test_y = []\n",
    "print(f'清洗前trian:{len(data_train_x)},清洗前trian_target:{len(data_train_y)}')\n",
    "for i in range(len(data_train_x)):\n",
    "    if data_train_x[i]!='':\n",
    "        clean_train_x.append(data_train_x[i])\n",
    "        clean_train_y.append(data_train_y[i])\n",
    "print(f'清洗後trian:{len(clean_train_x)},清洗後trian_target:{len(clean_train_y)}')\n",
    "\n",
    "print(f'清洗前test:{len(data_valid_x)},清洗前test:{len(data_valid_y)}')\n",
    "for i in range(len(data_valid_x)):\n",
    "    if data_valid_x[i]!='':\n",
    "        clean_vaild_x.append(data_valid_x[i])\n",
    "        clean_valid_y.append(data_valid_y[i])\n",
    "print(f'清洗後test:{len(clean_vaild_x)},清洗後test_target:{len(clean_valid_y)}')\n",
    "\n",
    "print(f'清洗前valid:{len(data_test_x)},清洗前valid:{len(data_test_y)}')\n",
    "for i in range(len(data_test_x)):\n",
    "    if data_test_x[i]!='':\n",
    "        clean_test_x.append(data_test_x[i])\n",
    "        clean_test_y.append(data_test_y[i])\n",
    "print(f'清洗後valid:{len(clean_test_x)},清洗後valid_target:{len(clean_test_y)}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 367705,
     "status": "ok",
     "timestamp": 1595645188171,
     "user": {
      "displayName": "蔡孟廷",
      "photoUrl": "",
      "userId": "16683234324658169721"
     },
     "user_tz": -480
    },
    "id": "Hr0pUskKobCw",
    "outputId": "b1fe24dc-a8bd-4abf-ff33-7d3ad478858c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test data file is exist\n"
     ]
    }
   ],
   "source": [
    "if(not os.path.isfile(\"seg_train_x.npy\")):\n",
    "    print(\"Train/Val/Test data file is not exist\")   \n",
    "    seg_train_x = []\n",
    "    seg_valid_x = []\n",
    "    seg_test_x = []\n",
    "    for i in range(len(clean_train_x)):\n",
    "        seg_train_x.append(' '.join([j for j in jieba.cut_for_search(clean_train_x[i]) if j not in stopwords]))\n",
    "    for i in range(len(clean_vaild_x)):\n",
    "        seg_valid_x.append(' '.join([j for j in jieba.cut_for_search(clean_vaild_x[i]) if j not in stopwords]))\n",
    "    for i in range(len(clean_test_x)):\n",
    "        seg_test_x.append(' '.join([j for j in jieba.cut_for_search(clean_test_x[i]) if j not in stopwords]))\n",
    "    seg_train_y = clean_train_y\n",
    "    seg_valid_y = clean_valid_y\n",
    "    seg_test_y = clean_test_y\n",
    "    np.save(\"seg_train_y\", seg_train_y)\n",
    "    np.save(\"seg_valid_y\", seg_valid_y)\n",
    "    np.save(\"seg_test_y\", seg_test_y)\n",
    "\n",
    "    np.save(\"seg_train_x\", seg_train_x)\n",
    "    np.save(\"seg_valid_x\", seg_valid_x)\n",
    "    np.save(\"seg_test_x\", seg_test_x)\n",
    "else:\n",
    "    print(\"Train/Val/Test data file is exist\")   \n",
    "    seg_train_x, seg_train_y = np.load(\"seg_train_x.npy\"),  np.load(\"seg_train_y.npy\")\n",
    "    seg_valid_x, seg_valid_y = np.load(\"seg_valid_x.npy\"),  np.load(\"seg_valid_y.npy\")\n",
    "    seg_test_x, seg_test_y = np.load(\"seg_test_x.npy\"),  np.load(\"seg_test_y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16137,
     "status": "ok",
     "timestamp": 1595645225441,
     "user": {
      "displayName": "蔡孟廷",
      "photoUrl": "",
      "userId": "16683234324658169721"
     },
     "user_tz": -480
    },
    "id": "UyyMkpwrobCz",
    "outputId": "7475555b-7e02-4058-c4a3-75b12a718c5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test data file is exist\n",
      ">> Train Data Shape : (13413, 500) ; Train Label Shape : (13413, 2)\n",
      ">> Val Data Shape : (5804, 500) ; Val Label Shape : (5804, 2)\n",
      ">> Test Data Shape : (270, 500) ; Test Label Shape : (270, 2)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "if(not os.path.isfile(\"train_x.npy\")):\n",
    "    print(\"Train/Val/Test data file is not exist\")   \n",
    "    vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(config.max_sequence_length, min_frequency=config.min_word_frequency)\n",
    "    train_x = np.array(list(vocab_processor.fit_transform(seg_train_x)))\n",
    "    train_y = tf.keras.utils.to_categorical(seg_train_y)\n",
    "    valid_x = np.array(list(vocab_processor.fit_transform(seg_valid_x)))\n",
    "    valid_y = tf.keras.utils.to_categorical(seg_valid_y)\n",
    "    test_x = np.array(list(vocab_processor.fit_transform(seg_test_x)))\n",
    "    test_y = tf.keras.utils.to_categorical(seg_test_y)\n",
    "    config.vocab_size = len(vocab_processor.vocabulary_)\n",
    "    \n",
    "    with open('vocab.txt', 'wt',encoding=\"utf-8\") as w_file:\n",
    "        for vocab in vocab_processor.vocabulary_._reverse_mapping:\n",
    "            w_file.write(vocab + \"\\n\")      \n",
    "    print(\"Total vocab size: {0}\".format(config.vocab_size))\n",
    "\n",
    "    np.save(\"train_x\", train_x); np.save(\"train_y\", train_y)\n",
    "    np.save(\"val_x\", valid_x) ; np.save(\"val_y\", valid_y)\n",
    "    np.save(\"test_x\", test_x) ; np.save(\"test_y\", test_y)\n",
    "else:\n",
    "    print(\"Train/Val/Test data file is exist\")   \n",
    "    train_x, train_y = np.load(\"train_x.npy\"),  np.load(\"train_y.npy\")\n",
    "    valid_x, valid_y = np.load(\"val_x.npy\"),  np.load(\"val_y.npy\")\n",
    "    test_x, test_y = np.load(\"test_x.npy\"),  np.load(\"test_y.npy\")\n",
    "    \n",
    "    config.vocab_size = sum(1 for line in open(\"vocab.txt\",encoding='utf-8'))\n",
    "\n",
    "config.category_num = train_y.shape[1]\n",
    "print('>> Train Data Shape : {0} ; Train Label Shape : {1}'.format(train_x.shape, train_y.shape))\n",
    "print('>> Val Data Shape : {0} ; Val Label Shape : {1}'.format(valid_x.shape, valid_y.shape))\n",
    "print('>> Test Data Shape : {0} ; Test Label Shape : {1}'.format(test_x.shape, test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QIOdQtgoobC1"
   },
   "source": [
    "# 建立架構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1077,
     "status": "ok",
     "timestamp": 1595645300410,
     "user": {
      "displayName": "蔡孟廷",
      "photoUrl": "",
      "userId": "16683234324658169721"
     },
     "user_tz": -480
    },
    "id": "qwIZE7HEobC5"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "    \n",
    "class TextRNN(object):\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        \n",
    "        # 四個等待輸入的data\n",
    "        self.batch_size = tf.placeholder(tf.int32, [] , name = 'batch_size')\n",
    "        self.keep_prob = tf.placeholder(tf.float32, [], name = 'keep_prob')\n",
    "        \n",
    "        # Initial\n",
    "        self.x = tf.placeholder(tf.int32, [None, self.config.max_sequence_length] , name = 'x')\n",
    "        self.y_label = tf.placeholder(tf.float32, [None, self.config.category_num], name = 'y_label')\n",
    "        self.choose_model = config.choose_model\n",
    "        self.rnn()\n",
    "    # Get LSTM Cell\n",
    "    def cell(self, num_units):\n",
    "        #BasicLSTMCell activity => default tanh\n",
    "        if self.choose_model == \"lstm\":\n",
    "            #可以設定peephole等屬性\n",
    "            LSTM_cell = rnn.LSTMCell( initializer = tf.random_uniform_initializer(-0.1, 0.1,seed=2 )) \n",
    "        elif self.choose_model == \"basic\":\n",
    "            #最基礎的，沒有peephole\n",
    "            LSTM_cell = rnn.BasicLSTMCell(num_units = num_units, forget_bias = 1.0, state_is_tuple = True) \n",
    "        else:\n",
    "            LSTM_cell = rnn.GRUCell(num_units)\n",
    "\n",
    "        return rnn.DropoutWrapper(LSTM_cell, output_keep_prob = self.keep_prob)\n",
    "    \n",
    "    def rnn(self):\n",
    "        \"\"\"RNN模型\"\"\"\n",
    "        # 詞向量映射\n",
    "        with tf.device('/cpu:0'):\n",
    "            embedding = tf.get_variable('embedding', [self.config.vocab_size, self.config.embedding_dim_size])\n",
    "            embedding_inputs = tf.nn.embedding_lookup(embedding, self.x)\n",
    "            \n",
    "        # RNN Layers\n",
    "        with tf.name_scope('layers'):\n",
    "            with tf.name_scope('RNN'):\n",
    "                LSTM_cells = rnn.MultiRNNCell([self.cell(int(self.config.num_units[_])) for _ in range(self.config.num_layer)])\n",
    "                # x_shape = tf.reshape(self.x, [-1, self.config.truncate, self.config.vectorSize])\n",
    "                \n",
    "            with tf.name_scope('output'):\n",
    "                init_state = LSTM_cells.zero_state(self.batch_size, dtype = tf.float32)\n",
    "                outputs, final_state = tf.nn.dynamic_rnn(LSTM_cells, inputs = embedding_inputs, \n",
    "                                                        initial_state = init_state, time_major = False, dtype = tf.float32)\n",
    "                \n",
    "        # Output Layer\n",
    "        with tf.name_scope('output_layer'):\n",
    "            # 全連接層，後面接dropout以及relu激活\n",
    "            fc1 = tf.layers.dense(outputs[:, -1, :], int(self.config.num_units[len(self.config.num_units)-1]))\n",
    "            fc1 = tf.contrib.layers.dropout(fc1, self.keep_prob)\n",
    "            fc1 = tf.nn.relu(fc1)\n",
    "                \n",
    "            # 分類器\n",
    "            y = tf.layers.dense(fc1, self.config.category_num, name = 'y')\n",
    "        \n",
    "        self.y_pred_cls = tf.argmax(y, axis = 1) #預測類別\n",
    "        with tf.name_scope('cross_entropy'):\n",
    "            with tf.name_scope('total'):\n",
    "                self.y=tf.nn.softmax(y)   \n",
    "                self.softmax = tf.nn.softmax_cross_entropy_with_logits(labels = self.y_label, logits = y)\n",
    "                self.cross_entropy = tf.reduce_mean(self.softmax)\n",
    "\n",
    "        with tf.name_scope('train'):\n",
    "            self.train_step = tf.train.AdamOptimizer(self.config.learning_rate).minimize(self.cross_entropy)\n",
    "\n",
    "        with tf.name_scope('accuracy'):\n",
    "            with tf.name_scope('correct_prediction'):\n",
    "                self.correction_prediction = tf.equal(self.y_pred_cls, tf.argmax(self.y_label, axis = 1))\n",
    "            with tf.name_scope('accuracy'):\n",
    "                self.accuracy = tf.reduce_mean(tf.cast(self.correction_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qmHw-Sn2obC7"
   },
   "source": [
    "# LSTM訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2013613,
     "status": "ok",
     "timestamp": 1595647314018,
     "user": {
      "displayName": "蔡孟廷",
      "photoUrl": "",
      "userId": "16683234324658169721"
     },
     "user_tz": -480
    },
    "id": "a9-mc2RqobC-",
    "outputId": "8dc80130-3355-4315-f9c2-9ee31fd95df0"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'num_units'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-8bf477584bc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-d1c4d298bcfb>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategory_num\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'y_label'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoose_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoose_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;31m# Get LSTM Cell\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_units\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-d1c4d298bcfb>\u001b[0m in \u001b[0;36mrnn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'layers'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RNN'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m                 \u001b[0mLSTM_cells\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiRNNCell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_units\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m                 \u001b[1;31m# x_shape = tf.reshape(self.x, [-1, self.config.truncate, self.config.vectorSize])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-d1c4d298bcfb>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'layers'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RNN'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m                 \u001b[0mLSTM_cells\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiRNNCell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_units\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m                 \u001b[1;31m# x_shape = tf.reshape(self.x, [-1, self.config.truncate, self.config.vectorSize])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-d1c4d298bcfb>\u001b[0m in \u001b[0;36mcell\u001b[1;34m(self, num_units)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoose_model\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"lstm\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;31m#可以設定peephole等屬性\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mLSTM_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSTMCell\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minitializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_uniform_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoose_model\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"basic\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;31m#最基礎的，沒有peephole\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\practice\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'num_units'"
     ]
    }
   ],
   "source": [
    "def get_time_dif(start_time):\n",
    "    \"\"\"得到已使用時間\"\"\"\n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "    \n",
    "    return timedelta(seconds = int(round(time_dif)))\n",
    "\n",
    "def feedData(x_batch, y_batch, keep_prob, batch_size, model):\n",
    "    feed_dict = {\n",
    "        model.x: x_batch,\n",
    "        model.y_label: y_batch,\n",
    "        model.keep_prob: keep_prob,\n",
    "        model.batch_size: batch_size\n",
    "    }\n",
    "    return feed_dict\n",
    "\n",
    "best_val_acc = -1.0 # 最佳驗證集準確度\n",
    "last_improved = 0 # 紀錄上一次提升batch \n",
    "require_improvement = 300  # 如果超过n輪未提升，提前结束訓練\n",
    "total_batch = 0  # 總批次\n",
    "print_per_batch = 100\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "model = TextRNN(config)\n",
    "start_time = time.time()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    flag = False\n",
    "    for epoch in range(config.epoch_size):\n",
    "        print('Epoch: {0}'.format(epoch + 1))\n",
    "        shuffled_ix = np.random.permutation(np.arange(len(train_x)))\n",
    "        train_x = train_x[shuffled_ix]\n",
    "        train_y = train_y[shuffled_ix]\n",
    "        for step in range(0, train_x.shape[0], config.batch_size):\n",
    "            batch_x, batch_y = train_x[step:step + config.batch_size], train_y[step:step + config.batch_size]\n",
    "            \n",
    "            if total_batch % print_per_batch == 0:  \n",
    "                train_loss, train_acc = sess.run([model.cross_entropy, model.accuracy], feed_dict = feedData(batch_x, batch_y, 1.0, batch_x.shape[0], model))\n",
    "                val_loss, val_acc = sess.run([model.cross_entropy, model.accuracy], feed_dict = feedData(valid_x, valid_y, 1.0, valid_x.shape[0], model))\n",
    "                \n",
    "                if val_acc > best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "                    last_improved = total_batch\n",
    "                    saver.save(sess = sess, save_path = config.save_path)\n",
    "                    improved_str = '*'\n",
    "                else:\n",
    "                    improved_str = ''\n",
    "                    \n",
    "                time_dif = get_time_dif(start_time)                               \n",
    "                msg = 'Iter: {0:>6}, Train Loss: {1:>6.3}, Train Acc: {2:>7.2%}, Val Loss: {3:>6.3}, Val Acc: {4:>7.2%}, Time: {5} {6}'\n",
    "                print(msg.format(total_batch, train_loss, train_acc, val_loss, val_acc, time_dif, improved_str))\n",
    "            \n",
    "            # train\n",
    "            sess.run(model.train_step, feed_dict = feedData(batch_x, batch_y, 1.0, batch_x.shape[0], model))\n",
    "            total_batch += 1\n",
    "            \n",
    "            if total_batch - last_improved > require_improvement:\n",
    "                # 驗證集準確度長期不提升，提前结束訓練\n",
    "                print(\"No optimization for a long time, auto-stopping...\")\n",
    "                flag = True\n",
    "                break  # 跳出循环\n",
    "\n",
    "        if flag:  # 同上\n",
    "            break\n",
    "    print(\"訓練完成...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 驗證集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5768,
     "status": "ok",
     "timestamp": 1595647346846,
     "user": {
      "displayName": "蔡孟廷",
      "photoUrl": "",
      "userId": "16683234324658169721"
     },
     "user_tz": -480
    },
    "id": "hOKaXmp-obDB",
    "outputId": "ba626090-3244-4782-9e89-3512ecc5104f"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'num_units'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-3e180524e41b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-d1c4d298bcfb>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategory_num\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'y_label'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoose_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoose_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;31m# Get LSTM Cell\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_units\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-d1c4d298bcfb>\u001b[0m in \u001b[0;36mrnn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'layers'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RNN'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m                 \u001b[0mLSTM_cells\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiRNNCell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_units\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m                 \u001b[1;31m# x_shape = tf.reshape(self.x, [-1, self.config.truncate, self.config.vectorSize])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-d1c4d298bcfb>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'layers'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RNN'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m                 \u001b[0mLSTM_cells\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiRNNCell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_units\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m                 \u001b[1;31m# x_shape = tf.reshape(self.x, [-1, self.config.truncate, self.config.vectorSize])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-d1c4d298bcfb>\u001b[0m in \u001b[0;36mcell\u001b[1;34m(self, num_units)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoose_model\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"lstm\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;31m#可以設定peephole等屬性\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mLSTM_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSTMCell\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minitializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_uniform_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoose_model\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"basic\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;31m#最基礎的，沒有peephole\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\practice\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'num_units'"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "def get_time_dif(start_time):\n",
    "    \"\"\"得到已使用時間\"\"\"\n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "    \n",
    "    return timedelta(seconds = int(round(time_dif)))\n",
    "def feedData(x_batch, y_batch, keep_prob, batch_size, model):\n",
    "    feed_dict = {\n",
    "        model.x: x_batch,\n",
    "        model.y_label: y_batch,\n",
    "        model.keep_prob: keep_prob,\n",
    "        model.batch_size: batch_size\n",
    "    }\n",
    "    return feed_dict\n",
    "tf.reset_default_graph()\n",
    "model = TextRNN(config)\n",
    "start_time = time.time()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess = sess, save_path = config.save_path)  # 讀取保存的模型\n",
    "    shuffled_ix = np.random.permutation(np.arange(len(test_x)))\n",
    "    test_x = test_x[shuffled_ix]\n",
    "    test_y = test_y[shuffled_ix]\n",
    "    test_loss, test_acc, test_predict_label,y,y_label = sess.run([model.cross_entropy, model.accuracy, model.y_pred_cls,model.y,model.y_label], feed_dict = feedData(test_x, test_y, 1.0, test_x.shape[0], model))\n",
    "    time_dif = get_time_dif(start_time)\n",
    "    msg = 'Test Loss: {0:>6.2}, Test Acc: {1:>7.2%}, Time: {2}'\n",
    "    print(msg.format(test_loss, test_acc, time_dif))\n",
    "    print(\"測試完成...\") \n",
    "    test_label = np.argmax(test_y, 1)\n",
    "    # 混淆矩陣\n",
    "    print(\">> Confusion Matrix...\")\n",
    "    cm = metrics.confusion_matrix(test_label, test_predict_label)\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "rnn_test2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
