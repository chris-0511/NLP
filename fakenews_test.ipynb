{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jieba\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict=[]\n",
    "with open('vocab.txt',encoding='utf-8') as f:\n",
    "    for i in f:\n",
    "        i=i.replace('\\n','')\n",
    "        vocab_dict.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=[]\n",
    "with open(r'./stop.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if len(line)>0:\n",
    "            stopwords.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    max_sequence_length = 500 # 最長序列長度為n個字\n",
    "    min_word_frequency = 3 # 出現頻率小於n的話 ; 就當成罕見字\n",
    "    \n",
    "    vocab_size = None\n",
    "    category_num = None\n",
    "    \n",
    "    choose_model = 'lstm' # 想要使用的模型 ex lstm; rnn; gru\n",
    "    embedding_dim_size =300 # 詞向量維度\n",
    "    num_layer = 1 # 層數\n",
    "    num_units = [128] # 神經元\n",
    "    learning_rate = 0.0001 # 學習率         \n",
    "    keep_prob = 0.8 \n",
    "    \n",
    "    batch_size = 64 # mini-batch\n",
    "    epoch_size = 30 # epoch\n",
    "    \n",
    "    save_path = 'best_validation' # 模型儲存檔名\n",
    "    \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans='你收到「領到3000消費券可以直接到全聯社換全聯禮券」、「他多加800塊給你總共3800」、「可到全聯社慢慢買」這樣的謠言訊息嗎？後續這樣的訊息貼文又出現了各種變形版本誤導。事實上關於政府所發行的「振興三倍券」並非消費券，且不能購買禮券，對此全聯福利中心也有在官方網站發出澄清，只是後來在社群媒體與通訊軟體又出現各種變形說法，務必以官方資料為主。'\n",
    "# ans='又到了四年一度的閏年。在許多歐洲國家，2月29日是女性專屬的求婚日，在這天求婚不只不會被貼上標籤，男生如果拒絕還得受罰！女性選在閏年向男性求婚的習俗從何而來？最常見的說法是源自5世紀的愛爾蘭。據傳聖布麗姬（St. Brigid）向聖派翠克主教（St. Patrick）抱怨，女生等男生求婚要等很久，於是主教就規定在閏年的2月29日，女性可以求婚。後來這項規範傳入蘇格蘭，瑪格麗特皇后（Queen Margaret）據此頒布法令，讓蘇格蘭女性可以在229當天向男性求婚，而且對方如過拒絕還要受罰。男生如果拒絕求婚，就要給女方一個吻或一件絲綢洋裝，或是一雙手套。在部分上層歐洲社會中，還要給到12雙手套，這樣才能讓女生把手遮起來，避免被別人發現沒戴婚戒。至於為什麼會有罰男方獻吻的說法，則是因為有一說是聖派翠克主教一答應讓女生求婚，聖布麗姬立刻下跪向主教求婚，主教拒絕了，但給她一個吻並送她一件絲綢長袍。不過上述故事應該都是杜撰的。聖布麗姬不一定是真實存在的人物，就算真有其人，聖派翠克主教過世的時候，聖布麗姬也還是個未滿10歲的小女孩。瑪格麗特皇后則是7歲就過世了，不太可能真的立過這條法令。女生229才能求婚引發平權爭議不管實際上是怎麼開始的，這套傳統就此傳承了下來。但隨著兩性平權的意識越來越普及，女性選在閏年求婚的說法也遭受了抨擊。熟悉這個傳統的美國學者柏金（Katherine Parkin）就認為，在這個女性地位逐漸提升的年代，特別准許女生每四年可以求婚一次，實在可笑，甚至有羞辱之嫌。但也有人認為，這項傳統的存在其實也是在鼓勵女性拋開傳統枷鎖，當她們所愛的人不敢開口的時候，勇敢站出來主導情勢，從這點來看或許也沒有這麼違反女權的概念。實際上還真的蠻多女生挑在229求婚的。2008年，來自英國的梅特卡夫（Sally Metcalf）就選在那一天向長跑10年的男友求婚成功。她說，「哪一天都好，不過在2月29日訂婚確實讓我覺得我們蠻特別的。」她也鼓勵其他女性不要再等了，直接開口問，只要對方愛你，就不該拒絕。在愛爾蘭和芬蘭，也有很多人相信229是個求婚幸運日，愛爾蘭更有一說是在229求婚可以降低未來的離婚機率。可惜沒有統計數據證明在閏年結婚或訂婚的人比較有可能白頭偕老，在男女平等的時代，誰開口似乎也沒那麼重要。但是女孩，如果妳一直找不到機會或提不起勇氣，不妨就選在這個連假給親愛的他一個驚喜吧！閏年傳統番外篇：有人相信229是幸運日，但也有人認為229這個多餘的日子很邪門。依據希臘傳統，如果在閏年結婚，以後就會離婚。選在閏年離婚的人，這輩子再也沒辦法找到幸福了。參考資料：華爾街日報、Irish Central、HuffPost、timeanddate.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你收到「領到3000消費券可以直接到全聯社換全聯禮券」、「他多加800塊給你總共3800」、「可到全聯社慢慢買」這樣的謠言訊息嗎？後續這樣的訊息貼文又出現了各種變形版本誤導。事實上關於政府所發行的「振興三倍券」並非消費券，且不能購買禮券，對此全聯福利中心也有在官方網站發出澄清，只是後來在社群媒體與通訊軟體又出現各種變形說法，務必以官方資料為主。'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'又到了四年一度的閏年在許多歐洲國家月日是女性專屬的求婚日在這天求婚不只不會被貼上標籤男生如果拒絕還得受罰女性選在閏年向男性求婚的習俗從何而來最常見的說法是源自世紀的愛爾蘭據傳聖布麗姬向聖派翠克主教抱怨女生等男生求婚要等很久於是主教就規定在閏年的月日女性可以求婚後來這項規範傳入蘇格蘭瑪格麗特皇后據此頒布法令讓蘇格蘭女性可以在當天向男性求婚而且對方如過拒絕還要受罰男生如果拒絕求婚就要給女方一個吻或一件絲綢洋裝或是一雙手套在部分上層歐洲社會中還要給到雙手套這樣才能讓女生把手遮起來避免被別人發現沒戴婚戒至於為什麼會有罰男方獻吻的說法則是因為有一說是聖派翠克主教一答應讓女生求婚聖布麗姬立刻下跪向主教求婚主教拒絕了但給她一個吻並送她一件絲綢長袍不過上述故事應該都是杜撰的聖布麗姬不一定是真實存在的人物就算真有其人聖派翠克主教過世的時候聖布麗姬也還是個未滿歲的小女孩瑪格麗特皇后則是歲就過世了不太可能真的立過這條法令女生才能求婚引發平權爭議不管實際上是怎麼開始的這套傳統就此傳承了下來但隨著兩性平權的意識越來越普及女性選在閏年求婚的說法也遭受了抨擊熟悉這個傳統的美國學者柏金就認為在這個女性地位逐漸提升的年代特別准許女生每四年可以求婚一次實在可笑甚至有羞辱之嫌但也有人認為這項傳統的存在其實也是在鼓勵女性拋開傳統枷鎖當她們所愛的人不敢開口的時候勇敢站出來主導情勢從這點來看或許也沒有這麼違反女權的概念實際上還真的蠻多女生挑在求婚的年來自英國的梅特卡夫就選在那一天向長跑年的男友求婚成功她說哪一天都好不過在月日訂婚確實讓我覺得我們蠻特別的她也鼓勵其他女性不要再等了直接開口問只要對方愛你就不該拒絕在愛爾蘭和芬蘭也有很多人相信是個求婚幸運日愛爾蘭更有一說是在求婚可以降低未來的離婚機率可惜沒有統計數據證明在閏年結婚或訂婚的人比較有可能白頭偕老在男女平等的時代誰開口似乎也沒那麼重要但是女孩如果妳一直找不到機會或提不起勇氣不妨就選在這個連假給親愛的他一個驚喜吧閏年傳統番外篇有人相信是幸運日但也有人認為這個多餘的日子很邪門依據希臘傳統如果在閏年結婚以後就會離婚選在閏年離婚的人這輩子再也沒辦法找到幸福了參考資料華爾街日報'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text_string):\n",
    "    text_string = re.sub(r'[^\\u4e00-\\u9fa5]+', '', text_string)\n",
    "    return(text_string)\n",
    "ans = clean_text(ans)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_seg=[]\n",
    "ans_seg.append([j for j in jieba.cut(ans, cut_all=False) if j not in stopwords])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=np.zeros(config.max_sequence_length)\n",
    "for i in ans_seg:\n",
    "    for j ,v in enumerate(i) :\n",
    "        for index ,value in enumerate(vocab_dict):\n",
    "            if v==value:\n",
    "                ans[j]=index\n",
    "ans=ans.reshape(-1,config.max_sequence_length)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    " \n",
    "train_x, train_y = np.load(\"train_x.npy\"),  np.load(\"train_y.npy\")\n",
    "config.vocab_size = sum(1 for line in open(r\"vocab.txt\",encoding='utf-8'))\n",
    "config.category_num = train_y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "    \n",
    "class TextRNN(object):\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        \n",
    "        # 四個等待輸入的data\n",
    "        self.batch_size = tf.placeholder(tf.int32, [] , name = 'batch_size')\n",
    "        self.keep_prob = tf.placeholder(tf.float32, [], name = 'keep_prob')\n",
    "        \n",
    "        # Initial\n",
    "        self.x = tf.placeholder(tf.int32, [None, self.config.max_sequence_length] , name = 'x')\n",
    "        self.y_label = tf.placeholder(tf.float32, [None, self.config.category_num], name = 'y_label')\n",
    "        self.choose_model = config.choose_model\n",
    "        self.rnn()\n",
    "    # Get LSTM Cell\n",
    "    def cell(self, num_units):\n",
    "        #BasicLSTMCell activity => default tanh\n",
    "        if self.choose_model == \"lstm\":\n",
    "            #可以設定peephole等屬性\n",
    "            LSTM_cell = rnn.LSTMCell(num_units, initializer = tf.random_uniform_initializer(-0.1, 0.1, seed = 2)) \n",
    "        elif self.choose_model == \"basic\":\n",
    "            #最基礎的，沒有peephole\n",
    "            LSTM_cell = rnn.BasicLSTMCell(num_units = num_units, forget_bias = 1.0, state_is_tuple = True) \n",
    "        else:\n",
    "            LSTM_cell = rnn.GRUCell(num_units)\n",
    "\n",
    "        return rnn.DropoutWrapper(LSTM_cell, output_keep_prob = self.keep_prob)\n",
    "    \n",
    "    def rnn(self):\n",
    "        \"\"\"RNN模型\"\"\"\n",
    "        # 詞向量映射\n",
    "        with tf.device('/cpu:0'):\n",
    "            embedding = tf.get_variable('embedding', [self.config.vocab_size, self.config.embedding_dim_size])\n",
    "            embedding_inputs = tf.nn.embedding_lookup(embedding, self.x)\n",
    "            self.emb=embedding_inputs\n",
    "        # RNN Layers\n",
    "        with tf.name_scope('layers'):\n",
    "            with tf.name_scope('RNN'):\n",
    "                LSTM_cells = rnn.MultiRNNCell([self.cell(int(self.config.num_units[_])) for _ in range(self.config.num_layer)])\n",
    "                # x_shape = tf.reshape(self.x, [-1, self.config.truncate, self.config.vectorSize])\n",
    "                \n",
    "            with tf.name_scope('output'):\n",
    "                init_state = LSTM_cells.zero_state(self.batch_size, dtype = tf.float32)\n",
    "                outputs, final_state = tf.nn.dynamic_rnn(LSTM_cells, inputs = embedding_inputs, \n",
    "                                                        initial_state = init_state, time_major = False, dtype = tf.float32)\n",
    "                \n",
    "        # Output Layer\n",
    "        with tf.name_scope('output_layer'):\n",
    "            # 全連接層，後面接dropout以及relu激活\n",
    "            fc1 = tf.layers.dense(outputs[:, -1, :], int(self.config.num_units[len(self.config.num_units)-1]))\n",
    "            fc1 = tf.contrib.layers.dropout(fc1, self.keep_prob)\n",
    "            fc1 = tf.nn.relu(fc1)\n",
    "                \n",
    "            # 分類器\n",
    "            y = tf.layers.dense(fc1, self.config.category_num, name = 'y')\n",
    "            \n",
    "        self.y_pred_cls = tf.argmax(y, axis = 1) #預測類別\n",
    "        with tf.name_scope('cross_entropy'):\n",
    "            with tf.name_scope('total'):\n",
    "                self.softmax = tf.nn.softmax_cross_entropy_with_logits(labels = self.y_label, logits = y)\n",
    "                self.cross_entropy = tf.reduce_mean(self.softmax)\n",
    "                self.y=tf.nn.softmax(y)  \n",
    "                self.cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = self.y_label, logits = y))\n",
    "                \n",
    "        with tf.name_scope('train'):\n",
    "            self.train_step = tf.train.AdamOptimizer(self.config.learning_rate).minimize(self.cross_entropy)\n",
    "\n",
    "        with tf.name_scope('accuracy'):\n",
    "            with tf.name_scope('correct_prediction'):\n",
    "                self.correction_prediction = tf.equal(self.y_pred_cls, tf.argmax(self.y_label, axis = 1))\n",
    "            with tf.name_scope('accuracy'):\n",
    "                self.accuracy = tf.reduce_mean(tf.cast(self.correction_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from best_validation\n",
      "有0.83的機率是真新聞唷\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def feedData1(x_batch, keep_prob, batch_size, model):\n",
    "    feed_dict1 = {\n",
    "        model.x: x_batch,\n",
    "#         model.y_label: y_batch,\n",
    "        model.keep_prob: keep_prob,\n",
    "        model.batch_size: batch_size\n",
    "    }\n",
    "    return feed_dict1\n",
    "tf.reset_default_graph()\n",
    "model = TextRNN(config)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess = sess, save_path = config.save_path)  # 讀取保存的模型\n",
    "    test_predict_label,y  = sess.run([ model.y_pred_cls,model.y], feed_dict = feedData1(ans, 1.0 ,len(ans), model))    \n",
    "    c=float(np.max(y))\n",
    "    if test_predict_label==0:\n",
    "        print('有%.2f的機率是假新聞'%(float(np.max(y))))\n",
    "    else:\n",
    "        print('有%.2f的機率是真新聞唷'%(float(np.max(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
